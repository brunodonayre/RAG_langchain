
# Sistema RAG con LangChain

Este repositorio contiene un ejemplo pr치ctico de un sistema **RAG (Retrieval-Augmented Generation)** utilizando la librer칤a [LangChain](https://www.langchain.com/) para conectar modelos de lenguaje con fuentes externas de conocimiento.

## 游늬 Archivos

- `13_1_Langchain_RAG.py`: Script principal con la implementaci칩n de RAG usando LangChain.
- `13_1_Langchain_RAG.ipynb`: Notebook original con explicaciones paso a paso.

## 游닍 Requisitos

Instala los paquetes necesarios:

```bash
pip install langchain openai faiss-cpu tiktoken
```

Tambi칠n puedes usar otras librer칤as como:

- `chromadb` o `weaviate` si deseas otros vectores.
- `dotenv` para manejar el API key.

## 丘뙖잺 Flujo de trabajo

1. **Carga de documentos:** Se leen archivos o textos desde una fuente local.
2. **Segmentaci칩n y Embedding:** Se convierten los textos en vectores usando un modelo de embeddings (por ejemplo `OpenAIEmbeddings`).
3. **Almacenamiento:** Los vectores se almacenan en una base de datos vectorial como FAISS.
4. **Recuperaci칩n + Generaci칩n (RAG):** Se recuperan los textos m치s relevantes y se los pasa al modelo LLM para generar respuestas contextualizadas.

## 游 Ejemplo de uso

```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import RetrievalQA

# Configura modelo y sistema RAG
qa = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0),
    retriever=vectorstore.as_retriever()
)

qa.run("쮺u치l es el prop칩sito del documento?")
```

## 游늷 Notas

- Se puede usar cualquier modelo de embeddings compatible (OpenAI, Hugging Face, Cohere, etc).
- Requiere una API Key v치lida de OpenAI (`OPENAI_API_KEY` en entorno o .env).

## 游 Sobre RAG

RAG combina recuperaci칩n de documentos relevantes con generaci칩n de texto para construir sistemas conversacionales m치s precisos y fundamentados.

## 游닆 Licencia

MIT. Los modelos de lenguaje y bases vectoriales est치n sujetos a sus propias licencias.
